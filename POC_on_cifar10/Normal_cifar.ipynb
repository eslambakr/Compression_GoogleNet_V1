{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Google_model_V1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2470,
     "status": "ok",
     "timestamp": 1555712902559,
     "user": {
      "displayName": "Mohamed Dawoud",
      "photoUrl": "",
      "userId": "09721841443558183270"
     },
     "user_tz": -120
    },
    "id": "p09YSOM3Rldw",
    "outputId": "c497cc15-47b5-4dc7-f22f-9ec05d549820"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "keras.backend.set_image_data_format('channels_first')\n",
    "from keras.layers.core import Layer\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True\n",
    "#sess = tf.Session(config=config)\n",
    "#K.set_session(sess)\n",
    "#K.set_learning_phase(1)\n",
    "import imageio\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import ZeroPadding2D, Dropout, Flatten, concatenate, Reshape, Activation, Softmax\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 3, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# configration:\n",
    "image_channels = 3\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing images (32-->224) and sample 10k from it.\n",
    "resized_img = []\n",
    "for i in range(10000):\n",
    "    resized_img.append(cv2.resize(np.swapaxes(x_train[i],0,-1),(image_width, image_height)))\n",
    "x_train = np.swapaxes(resized_img,1,-1)\n",
    "\n",
    "resized_img = []\n",
    "for i in range(10000):\n",
    "    resized_img.append(cv2.resize(np.swapaxes(x_test[i],0,-1),(image_width, image_height)))\n",
    "x_test = np.swapaxes(resized_img,1,-1)\n",
    "\n",
    "# sample from labels\n",
    "y_train = y_train[:10000]\n",
    "y_test = y_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10, 3)\n",
      "(10000, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "# duplicate labels as we have 3 output heads\n",
    "temp = []\n",
    "temp.append(y_train)\n",
    "temp.append(y_train)\n",
    "temp.append(y_train)\n",
    "print(np.swapaxes(np.swapaxes(np.asarray(temp),0,1),1,2).shape)\n",
    "y_train = np.swapaxes(np.swapaxes(np.asarray(temp),0,1),1,2)\n",
    "\n",
    "temp = []\n",
    "temp.append(y_test)\n",
    "temp.append(y_test)\n",
    "temp.append(y_test)\n",
    "print(np.swapaxes(np.swapaxes(np.asarray(temp),0,1),1,2).shape)\n",
    "y_test = np.swapaxes(np.swapaxes(np.asarray(temp),0,1),1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29787,
     "status": "ok",
     "timestamp": 1555715770287,
     "user": {
      "displayName": "Mohamed Dawoud",
      "photoUrl": "",
      "userId": "09721841443558183270"
     },
     "user_tz": -120
    },
    "id": "srTedGGhBkVH",
    "outputId": "118ed29f-36ec-4112-9c87-9aeee9411b72"
   },
   "outputs": [],
   "source": [
    "class LRN2D(Layer):\n",
    "    \"\"\"\n",
    "    This code is adapted from pylearn2.\n",
    "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.0001, k=1, beta=0.75, n=5, **kwargs):\n",
    "        if n % 2 == 0:\n",
    "            raise NotImplementedError(\"LRN2D only works with odd n. n provided: \" + str(n))\n",
    "        super(LRN2D, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "\n",
    "    def call(self, X):\n",
    "        b, ch, r, c = K.int_shape(X)\n",
    "        half_n = self.n // 2\n",
    "        input_sqr = K.square(X)\n",
    "        if b == None:\n",
    "          extra_channels = K.zeros((ch + 2 * half_n, r, c), dtype = 'float32')\n",
    "          extra_channels = K.expand_dims(extra_channels, axis = 0)\n",
    "        else:\n",
    "          extra_channels = K.zeros((b, ch + 2 * half_n, r, c), dtype = 'float32')\n",
    "        input_sqr = K.concatenate([extra_channels[:, :half_n, :, :],\n",
    "                                   input_sqr,\n",
    "                                   extra_channels[:, half_n + ch:, :, :]],\n",
    "                                   axis=1)\n",
    "        scale = self.k\n",
    "        norm_alpha = self.alpha / self.n\n",
    "        for i in range(0, self.n):\n",
    "            scale += norm_alpha * input_sqr[:, i:i + ch, :, :]\n",
    "        scale = scale ** self.beta\n",
    "        X = X / scale\n",
    "        return X\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__,\n",
    "                  \"alpha\": self.alpha,\n",
    "                  \"k\": self.k,\n",
    "                  \"beta\": self.beta,\n",
    "                  \"n\": self.n}\n",
    "        base_config = super(LRN2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    \n",
    "class PoolHelper(Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(PoolHelper, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        return x[:,:,1:,1:]\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = super(PoolHelper, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29395,
     "status": "ok",
     "timestamp": 1555715773708,
     "user": {
      "displayName": "Mohamed Dawoud",
      "photoUrl": "",
      "userId": "09721841443558183270"
     },
     "user_tz": -120
    },
    "id": "gdJRS4SuCCod",
    "outputId": "62dfb0d8-8c69-4019-f380-009fb249aad2"
   },
   "outputs": [],
   "source": [
    "def create_googlenet(trainable = True):\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "\n",
    "        input_image = Input(shape=(image_channels, image_width, image_height))\n",
    "\n",
    "        conv1_7x7_s2 = Conv2D(64,(7,7),strides=(2,2),padding='same',activation='relu',name='conv1/7x7_s2',kernel_regularizer=l2(0.0002), trainable = trainable)(input_image)\n",
    "\n",
    "        conv1_zero_pad = ZeroPadding2D(padding=(1, 1), trainable = trainable)(conv1_7x7_s2)\n",
    "\n",
    "        pool1_helper = PoolHelper()(conv1_zero_pad)\n",
    "\n",
    "        pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='valid',name='pool1/3x3_s2', trainable = trainable)(pool1_helper)\n",
    "\n",
    "        pool1_norm1 = LRN2D(name = 'LRN_1')(pool1_3x3_s2)\n",
    "\n",
    "        conv2_3x3_reduce = Conv2D(64,(1,1),padding='same',activation='relu',name='conv2/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(pool1_norm1)\n",
    "\n",
    "        conv2_3x3 = Conv2D(192,(3,3),padding='same',activation='relu',name='conv2/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(conv2_3x3_reduce)\n",
    "\n",
    "        conv2_norm2 = LRN2D(name = 'LRN_2')(conv2_3x3)\n",
    "\n",
    "        conv2_zero_pad = ZeroPadding2D(padding=(1, 1), trainable = trainable)(conv2_norm2)\n",
    "\n",
    "        pool2_helper = PoolHelper()(conv2_zero_pad)\n",
    "\n",
    "        pool2_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='valid',name='pool2/3x3_s2', trainable = trainable)(pool2_helper)\n",
    "\n",
    "        inception_3a_1x1 = Conv2D(64,(1,1),padding='same',activation='relu',name='inception_3a/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(pool2_3x3_s2)\n",
    "\n",
    "        inception_3a_3x3_reduce = Conv2D(96,(1,1),padding='same',activation='relu',name='inception_3a/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(pool2_3x3_s2)\n",
    "\n",
    "        inception_3a_3x3 = Conv2D(128,(3,3),padding='same',activation='relu',name='inception_3a/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3a_3x3_reduce)\n",
    "\n",
    "        inception_3a_5x5_reduce = Conv2D(16,(1,1),padding='same',activation='relu',name='inception_3a/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(pool2_3x3_s2)\n",
    "\n",
    "        inception_3a_5x5 = Conv2D(32,(5,5),padding='same',activation='relu',name='inception_3a/5x5',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3a_5x5_reduce)\n",
    "\n",
    "        inception_3a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_3a/pool', trainable = trainable)(pool2_3x3_s2)\n",
    "\n",
    "        inception_3a_pool_proj = Conv2D(32,(1,1),padding='same',activation='relu',name='inception_3a/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3a_pool)\n",
    "\n",
    "        inception_3a_output = concatenate([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj],axis=1)\n",
    "\n",
    "        inception_3b_1x1 = Conv2D(128,(1,1),padding='same',activation='relu',name='inception_3b/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3a_output)\n",
    "\n",
    "        inception_3b_3x3_reduce = Conv2D(128,(1,1),padding='same',activation='relu',name='inception_3b/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3a_output)\n",
    "\n",
    "        inception_3b_3x3 = Conv2D(192,(3,3),padding='same',activation='relu',name='inception_3b/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3b_3x3_reduce)\n",
    "\n",
    "        inception_3b_5x5_reduce = Conv2D(32,(1,1),padding='same',activation='relu',name='inception_3b/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3a_output)\n",
    "\n",
    "        inception_3b_5x5 = Conv2D(96,(5,5),padding='same',activation='relu',name='inception_3b/5x5',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3b_5x5_reduce)\n",
    "\n",
    "        inception_3b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_3b/pool', trainable = trainable)(inception_3a_output)\n",
    "\n",
    "        inception_3b_pool_proj = Conv2D(64,(1,1),padding='same',activation='relu',name='inception_3b/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_3b_pool)\n",
    "\n",
    "        inception_3b_output = concatenate([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj],axis=1)\n",
    "\n",
    "        inception_3b_output_zero_pad = ZeroPadding2D(padding=(1, 1), trainable = trainable)(inception_3b_output)\n",
    "\n",
    "        pool3_helper = PoolHelper()(inception_3b_output_zero_pad)\n",
    "\n",
    "        pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='valid',name='pool3/3x3_s2', trainable = trainable)(pool3_helper)\n",
    "\n",
    "        inception_4a_1x1 = Conv2D(192,(1,1),padding='same',activation='relu',name='inception_4a/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(pool3_3x3_s2)\n",
    "\n",
    "        inception_4a_3x3_reduce = Conv2D(96,(1,1),padding='same',activation='relu',name='inception_4a/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(pool3_3x3_s2)\n",
    "\n",
    "        inception_4a_3x3 = Conv2D(208,(3,3),padding='same',activation='relu',name='inception_4a/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4a_3x3_reduce)\n",
    "\n",
    "        inception_4a_5x5_reduce = Conv2D(16,(1,1),padding='same',activation='relu',name='inception_4a/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(pool3_3x3_s2)\n",
    "\n",
    "        inception_4a_5x5 = Conv2D(48,(5,5),padding='same',activation='relu',name='inception_4a/5x5',kernel_regularizer=l2(0.0002))(inception_4a_5x5_reduce)\n",
    "\n",
    "        inception_4a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_4a/pool', trainable = trainable)(pool3_3x3_s2)\n",
    "\n",
    "        inception_4a_pool_proj = Conv2D(64,(1,1),padding='same',activation='relu',name='inception_4a/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4a_pool)\n",
    "\n",
    "        inception_4a_output = concatenate([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj],axis=1)\n",
    "\n",
    "        loss1_ave_pool = AveragePooling2D(pool_size=(5,5),strides=(3,3),name='loss1/ave_pool', trainable = trainable)(inception_4a_output)\n",
    "\n",
    "        loss1_conv = Conv2D(128,(1,1),padding='same',activation='relu',name='loss1/conv',kernel_regularizer=l2(0.0002), trainable = trainable)(loss1_ave_pool)\n",
    "\n",
    "        loss1_flat = Flatten()(loss1_conv)\n",
    "\n",
    "        loss1_fc = Dense(1024,activation='relu',name='loss1/fc',kernel_regularizer=l2(0.0002), trainable = trainable)(loss1_flat)\n",
    "\n",
    "        loss1_drop_fc = Dropout(0.7, trainable = trainable)(loss1_fc)\n",
    "\n",
    "        loss1_classifier = Dense(1000, name='loss1/classifier',kernel_regularizer=l2(0.0002), trainable = trainable)(loss1_drop_fc)\n",
    "\n",
    "        loss1_classifier_act = Activation('softmax', name = 'head1')(loss1_classifier)\n",
    "\n",
    "\n",
    "        inception_4b_1x1 = Conv2D(160,(1,1),padding='same',activation='relu',name='inception_4b/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4a_output)\n",
    "\n",
    "        inception_4b_3x3_reduce = Conv2D(112,(1,1),padding='same',activation='relu',name='inception_4b/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4a_output)\n",
    "\n",
    "        inception_4b_3x3 = Conv2D(224,(3,3),padding='same',activation='relu',name='inception_4b/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4b_3x3_reduce)\n",
    "\n",
    "        inception_4b_5x5_reduce = Conv2D(24,(1,1),padding='same',activation='relu',name='inception_4b/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4a_output)\n",
    "\n",
    "        inception_4b_5x5 = Conv2D(64,(5,5),padding='same',activation='relu',name='inception_4b/5x5',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4b_5x5_reduce)\n",
    "\n",
    "        inception_4b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_4b/pool', trainable = trainable)(inception_4a_output)\n",
    "\n",
    "        inception_4b_pool_proj = Conv2D(64,(1,1),padding='same',activation='relu',name='inception_4b/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4b_pool)\n",
    "\n",
    "        inception_4b_output = concatenate([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj],axis=1)\n",
    "\n",
    "\n",
    "        inception_4c_1x1 = Conv2D(128,(1,1),padding='same',activation='relu',name='inception_4c/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4b_output)\n",
    "\n",
    "        inception_4c_3x3_reduce = Conv2D(128,(1,1),padding='same',activation='relu',name='inception_4c/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4b_output)\n",
    "\n",
    "        inception_4c_3x3 = Conv2D(256,(3,3),padding='same',activation='relu',name='inception_4c/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4c_3x3_reduce)\n",
    "\n",
    "        inception_4c_5x5_reduce = Conv2D(24,(1,1),padding='same',activation='relu',name='inception_4c/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4b_output)\n",
    "\n",
    "        inception_4c_5x5 = Conv2D(64,(5,5),padding='same',activation='relu',name='inception_4c/5x5',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4c_5x5_reduce)\n",
    "\n",
    "        inception_4c_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_4c/pool', trainable = trainable)(inception_4b_output)\n",
    "\n",
    "        inception_4c_pool_proj = Conv2D(64,(1,1),padding='same',activation='relu',name='inception_4c/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4c_pool)\n",
    "\n",
    "        inception_4c_output = concatenate([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj],axis=1)\n",
    "\n",
    "\n",
    "        inception_4d_1x1 = Conv2D(112,(1,1),padding='same',activation='relu',name='inception_4d/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4c_output)\n",
    "\n",
    "        inception_4d_3x3_reduce = Conv2D(144,(1,1),padding='same',activation='relu',name='inception_4d/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4c_output)\n",
    "\n",
    "        inception_4d_3x3 = Conv2D(288,(3,3),padding='same',activation='relu',name='inception_4d/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4d_3x3_reduce)\n",
    "\n",
    "        inception_4d_5x5_reduce = Conv2D(32,(1,1),padding='same',activation='relu',name='inception_4d/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4c_output)\n",
    "\n",
    "        inception_4d_5x5 = Conv2D(64,(5,5),padding='same',activation='relu',name='inception_4d/5x5',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4d_5x5_reduce)\n",
    "\n",
    "        inception_4d_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_4d/pool', trainable = trainable)(inception_4c_output)\n",
    "\n",
    "        inception_4d_pool_proj = Conv2D(64,(1,1),padding='same',activation='relu',name='inception_4d/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4d_pool)\n",
    "\n",
    "        inception_4d_output = concatenate([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj],axis=1)\n",
    "\n",
    "\n",
    "        loss2_ave_pool = AveragePooling2D(pool_size=(5,5),strides=(3,3),name='loss2/ave_pool', trainable = trainable)(inception_4d_output)\n",
    "\n",
    "        loss2_conv = Conv2D(128,(1,1),padding='same',activation='relu',name='loss2/conv',kernel_regularizer=l2(0.0002), trainable = trainable)(loss2_ave_pool)\n",
    "\n",
    "        loss2_flat = Flatten()(loss2_conv)\n",
    "\n",
    "        loss2_fc = Dense(1024,activation='relu',name='loss2/fc',kernel_regularizer=l2(0.0002), trainable = trainable)(loss2_flat)\n",
    "\n",
    "        loss2_drop_fc = Dropout(0.7, trainable = trainable)(loss2_fc)\n",
    "\n",
    "        loss2_classifier = Dense(1000, name='loss2/classifier',kernel_regularizer=l2(0.0002), trainable = trainable)(loss2_drop_fc)\n",
    "\n",
    "        loss2_classifier_act = Activation('softmax', name = 'head2')(loss2_classifier)\n",
    "\n",
    "\n",
    "        inception_4e_1x1 = Conv2D(256,(1,1),padding='same',activation='relu',name='inception_4e/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4d_output)\n",
    "\n",
    "        inception_4e_3x3_reduce = Conv2D(160,(1,1),padding='same',activation='relu',name='inception_4e/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4d_output)\n",
    "\n",
    "        inception_4e_3x3 = Conv2D(320,(3,3),padding='same',activation='relu',name='inception_4e/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4e_3x3_reduce)\n",
    "\n",
    "        inception_4e_5x5_reduce = Conv2D(32,(1,1),padding='same',activation='relu',name='inception_4e/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4d_output)\n",
    "\n",
    "        inception_4e_5x5 = Conv2D(128,(5,5),padding='same',activation='relu',name='inception_4e/5x5',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4e_5x5_reduce)\n",
    "\n",
    "        inception_4e_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_4e/pool', trainable = trainable)(inception_4d_output)\n",
    "\n",
    "        inception_4e_pool_proj = Conv2D(128,(1,1),padding='same',activation='relu',name='inception_4e/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_4e_pool)\n",
    "\n",
    "        inception_4e_output = concatenate([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj],axis=1)\n",
    "\n",
    "\n",
    "        inception_4e_output_zero_pad = ZeroPadding2D(padding=(1, 1), trainable = trainable)(inception_4e_output)\n",
    "\n",
    "        pool4_helper = PoolHelper()(inception_4e_output_zero_pad)\n",
    "\n",
    "        pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='valid',name='pool4/3x3_s2', trainable = trainable)(pool4_helper)\n",
    "\n",
    "\n",
    "        inception_5a_1x1 = Conv2D(256,(1,1),padding='same',activation='relu',name='inception_5a/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(pool4_3x3_s2)\n",
    "\n",
    "        inception_5a_3x3_reduce = Conv2D(160,(1,1),padding='same',activation='relu',name='inception_5a/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(pool4_3x3_s2)\n",
    "\n",
    "        inception_5a_3x3 = Conv2D(320,(3,3),padding='same',activation='relu',name='inception_5a/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5a_3x3_reduce)\n",
    "\n",
    "        inception_5a_5x5_reduce = Conv2D(32,(1,1),padding='same',activation='relu',name='inception_5a/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(pool4_3x3_s2)\n",
    "\n",
    "        inception_5a_5x5 = Conv2D(128,(5,5),padding='same',activation='relu',name='inception_5a/5x5',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5a_5x5_reduce)\n",
    "\n",
    "        inception_5a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_5a/pool', trainable = trainable)(pool4_3x3_s2)\n",
    "\n",
    "        inception_5a_pool_proj = Conv2D(128,(1,1),padding='same',activation='relu',name='inception_5a/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5a_pool)\n",
    "\n",
    "        inception_5a_output = concatenate([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj],axis=1)\n",
    "\n",
    "\n",
    "        inception_5b_1x1 = Conv2D(384,(1,1),padding='same',activation='relu',name='inception_5b/1x1',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5a_output)\n",
    "\n",
    "        inception_5b_3x3_reduce = Conv2D(192,(1,1),padding='same',activation='relu',name='inception_5b/3x3_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5a_output)\n",
    "\n",
    "        inception_5b_3x3 = Conv2D(384,(3,3),padding='same',activation='relu',name='inception_5b/3x3',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5b_3x3_reduce)\n",
    "\n",
    "        inception_5b_5x5_reduce = Conv2D(48,(1,1),padding='same',activation='relu',name='inception_5b/5x5_reduce',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5a_output)\n",
    "\n",
    "        inception_5b_5x5 = Conv2D(128,(5,5),padding='same',activation='relu',name='inception_5b/5x5',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5b_5x5_reduce)\n",
    "\n",
    "        inception_5b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_5b/pool', trainable = trainable)(inception_5a_output)\n",
    "\n",
    "        inception_5b_pool_proj = Conv2D(128,(1,1),padding='same',activation='relu',name='inception_5b/pool_proj',kernel_regularizer=l2(0.0002), trainable = trainable)(inception_5b_pool)\n",
    "\n",
    "        inception_5b_output = concatenate([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj],axis=1)\n",
    "\n",
    "\n",
    "        pool5_7x7_s1 = AveragePooling2D(pool_size=(7,7),strides=(1,1),name='pool5/7x7_s2', trainable = trainable)(inception_5b_output)\n",
    "\n",
    "        loss3_flat = Flatten()(pool5_7x7_s1)\n",
    "\n",
    "        pool5_drop_7x7_s1 = Dropout(0.4, trainable = trainable)(loss3_flat)\n",
    "\n",
    "        loss3_classifier = Dense(1000, name='loss3/classifier',kernel_regularizer=l2(0.0002), trainable = trainable)(pool5_drop_7x7_s1)\n",
    "\n",
    "        loss3_classifier_act = Activation('softmax', name='prob')(loss3_classifier)\n",
    "\n",
    "\n",
    "        googlenet = Model(inputs = input_image, outputs = [loss1_classifier_act, loss2_classifier_act, loss3_classifier_act])\n",
    "        \n",
    "\n",
    "        return googlenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (10000, 3, 224, 224), y.shape = (3, 10000, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ad7711de9b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Fit the model on the batches generated by datagen.flow().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     model.fit_generator(datagen.flow(x_train, [y_train,y_train,y_train], batch_size=batch_size),\n\u001b[0m\u001b[1;32m     50\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         )\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m     78\u001b[0m                              \u001b[0;34m'should have the same length. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                              \u001b[0;34m'Found: x.shape = %s, y.shape = %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                              (np.asarray(x).shape, np.asarray(y).shape))\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             raise ValueError('`x` (images tensor) and `sample_weight` '\n",
      "\u001b[0;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (10000, 3, 224, 224), y.shape = (3, 10000, 10)"
     ]
    }
   ],
   "source": [
    "model = create_googlenet(trainable = True)\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', loss_weights = [0.3, 0.3, 1], metrics=['accuracy'])\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, [y_train,y_train,y_train], batch_size=batch_size),\n",
    "                        steps_per_epoch = 10000/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, [y_test,y_test,y_test]),\n",
    "                        workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model on one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZbCMiQeDLZh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 3, 224, 224)\n",
      "0.7746236324310303\n",
      "Predicted: [[('n02127052', 'lynx', 0.43880922), ('n02123597', 'Siamese_cat', 0.12934858), ('n02328150', 'Angora', 0.12507504), ('n02123394', 'Persian_cat', 0.11460775), ('n02120079', 'Arctic_fox', 0.06618385)]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting and testing the pretrained model\n",
    "master_model = create_googlenet(trainable = False)\n",
    "master_model.load_weights('googlenet_weights_TF.h5')\n",
    "#img = scipy.misc.imresize(imageio.imread('/content/gdrive/My Drive/OneLab_Work/Copy of candel.jpeg'), [224, 224]).astype(np.float32)\n",
    "img = cv2.resize(cv2.imread('TEST4.jpg'), (224, 224)).astype(np.float32)\n",
    "print(img.shape)\n",
    "img[:, :, 0] -= 123.68\n",
    "img[:, :, 1] -= 116.77\n",
    "img[:, :, 2] -= 103.939\n",
    "img[:,:,[0,1,2]] = img[:,:,[2,1,0]]\n",
    "img = img.transpose((2, 0, 1))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "test = np.zeros((32, 3, 224, 224))\n",
    "test[0] = img\n",
    "print(img.shape)\n",
    "start = time.time()\n",
    "out = master_model.predict(img) # note: the model has three outputs\n",
    "print(time.time()-start)\n",
    "print('Predicted:', decode_predictions(out[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30309,
     "status": "ok",
     "timestamp": 1555715777213,
     "user": {
      "displayName": "Mohamed Dawoud",
      "photoUrl": "",
      "userId": "09721841443558183270"
     },
     "user_tz": -120
    },
    "id": "hOedlSFKQXTZ",
    "outputId": "bdfb4346-97e1-48ae-f103-6a2c27f8c426"
   },
   "outputs": [],
   "source": [
    "#master_model = create_googlenet('googlenet_weights_TF.h5', trainable = False)\n",
    "#slave_model = create_googlenet(trainable = True)\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#slave_model.compile(optimizer=sgd, loss='categorical_crossentropy', loss_weights = [0.3, 0.3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMgbtePA3PpV"
   },
   "outputs": [],
   "source": [
    "layer_names = [\"conv1/7x7_s2\",\n",
    "\"conv2/3x3_reduce\",\n",
    "\"conv2/3x3\",\n",
    "\"inception_3a/1x1\",\n",
    "\"inception_3a/3x3_reduce\",\n",
    "\"inception_3a/3x3\",\n",
    "\"inception_3a/5x5_reduce\",\n",
    "\"inception_3a/5x5\",\n",
    "\"inception_3a/pool_proj\",\n",
    "\"inception_3b/1x1\",\n",
    "\"inception_3b/3x3_reduce\",\n",
    "\"inception_3b/3x3\",\n",
    "\"inception_3b/5x5_reduce\",\n",
    "\"inception_3b/5x5\",\n",
    "\"inception_3b/pool_proj\",\n",
    "\"inception_4a/1x1\",\n",
    "\"inception_4a/3x3_reduce\",\n",
    "\"inception_4a/3x3\",\n",
    "\"inception_4a/5x5_reduce\",\n",
    "\"inception_4a/5x5\",\n",
    "\"inception_4a/pool_proj\",\n",
    "\"loss1/conv\",\n",
    "\"loss1/fc\",\n",
    "\"loss1/classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "    images = glob.glob(\"D:/GPU_User3/Dataset/All_Images/*.jpeg\")\n",
    "    batch = np.zeros((32, 3, 224, 224))\n",
    "    normalization = np.zeros((224, 224, 3))\n",
    "    normalization[:, :, 0] = 123.68\n",
    "    normalization[:, :, 1] = 116.779\n",
    "    normalization[:, :, 2] = 103.939\n",
    "    labels = np.zeros((32, 1000, 3), dtype = np.uint8)\n",
    "    model_output = np.zeros((32, 1000, 3), dtype = np.float32)\n",
    "    #garbage = []\n",
    "\n",
    "    while 1:\n",
    "        for img in range(0, 32):\n",
    "            frame = np.asarray((Image.fromarray(imageio.imread(images[img])).resize((224, 224)).convert(\"RGB\")), dtype = np.float32) - normalization\n",
    "\n",
    "            frame[:, :, [0, 1, 2]] = frame[:, :, [2, 1, 0]]\n",
    "            batch[img] = frame.transpose((2, 0, 1))\n",
    "\n",
    "        labels_temp = np.asarray(master_model.predict(batch)).transpose((1, 2, 0))\n",
    "        truth = np.max(labels[:, :, -1])\n",
    "        labels[:, labels_temp == truth, :] = 1\n",
    "        model_output = np.asarray(master_model.predict(batch)).transpose((1, 2, 0))\n",
    "        truth_location = np.argmax(model_output[:, :, -1], axis = 1)\n",
    "        for i in range(0, 32): labels[i, truth_location[i], :] = 1\n",
    "        \n",
    "        yield batch, [labels[:, :, 0], labels[:, :, 1], labels[:, :, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    slave_model = create_googlenet('googlenet_weights_TF.h5', trainable = True)\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    slave_model.compile(optimizer=sgd, loss='categorical_crossentropy', loss_weights = {\"prob\": 1,\n",
    "                                                                                        \"head2\": 0.3,\n",
    "                                                                                        \"head1\": 0.3})\n",
    "\n",
    "    master_model = create_googlenet('googlenet_weights_TF.h5', trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 64, 112, 112) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 64, 114, 114) 0           conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_1 (PoolHelper)      (None, 64, 114, 114) 0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool1/3x3_s2 (MaxPooling2D)     (None, 64, 56, 56)   0           pool_helper_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "LRN_1 (LRN2D)                   (None, 64, 56, 56)   0           pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3x3_reduce (Conv2D)       (None, 64, 56, 56)   4160        LRN_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3x3 (Conv2D)              (None, 192, 56, 56)  110784      conv2/3x3_reduce[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "LRN_2 (LRN2D)                   (None, 192, 56, 56)  0           conv2/3x3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 192, 58, 58)  0           LRN_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_2 (PoolHelper)      (None, 192, 58, 58)  0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool2/3x3_s2 (MaxPooling2D)     (None, 192, 28, 28)  0           pool_helper_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/3x3_reduce (Conv2D (None, 96, 28, 28)   18528       pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/5x5_reduce (Conv2D (None, 16, 28, 28)   3088        pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/pool (MaxPooling2D (None, 192, 28, 28)  0           pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/1x1 (Conv2D)       (None, 64, 28, 28)   12352       pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/3x3 (Conv2D)       (None, 128, 28, 28)  110720      inception_3a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/5x5 (Conv2D)       (None, 32, 28, 28)   12832       inception_3a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/pool_proj (Conv2D) (None, 32, 28, 28)   6176        inception_3a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 28, 28)  0           inception_3a/1x1[0][0]           \n",
      "                                                                 inception_3a/3x3[0][0]           \n",
      "                                                                 inception_3a/5x5[0][0]           \n",
      "                                                                 inception_3a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/3x3_reduce (Conv2D (None, 128, 28, 28)  32896       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/5x5_reduce (Conv2D (None, 32, 28, 28)   8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/pool (MaxPooling2D (None, 256, 28, 28)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/1x1 (Conv2D)       (None, 128, 28, 28)  32896       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/3x3 (Conv2D)       (None, 192, 28, 28)  221376      inception_3b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/5x5 (Conv2D)       (None, 96, 28, 28)   76896       inception_3b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/pool_proj (Conv2D) (None, 64, 28, 28)   16448       inception_3b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 480, 28, 28)  0           inception_3b/1x1[0][0]           \n",
      "                                                                 inception_3b/3x3[0][0]           \n",
      "                                                                 inception_3b/5x5[0][0]           \n",
      "                                                                 inception_3b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 480, 30, 30)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_3 (PoolHelper)      (None, 480, 30, 30)  0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool3/3x3_s2 (MaxPooling2D)     (None, 480, 14, 14)  0           pool_helper_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/3x3_reduce (Conv2D (None, 96, 14, 14)   46176       pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/5x5_reduce (Conv2D (None, 16, 14, 14)   7696        pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/pool (MaxPooling2D (None, 480, 14, 14)  0           pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/1x1 (Conv2D)       (None, 192, 14, 14)  92352       pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/3x3 (Conv2D)       (None, 208, 14, 14)  179920      inception_4a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/5x5 (Conv2D)       (None, 48, 14, 14)   19248       inception_4a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/pool_proj (Conv2D) (None, 64, 14, 14)   30784       inception_4a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 14, 14)  0           inception_4a/1x1[0][0]           \n",
      "                                                                 inception_4a/3x3[0][0]           \n",
      "                                                                 inception_4a/5x5[0][0]           \n",
      "                                                                 inception_4a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/3x3_reduce (Conv2D (None, 112, 14, 14)  57456       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/5x5_reduce (Conv2D (None, 24, 14, 14)   12312       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/pool (MaxPooling2D (None, 512, 14, 14)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/1x1 (Conv2D)       (None, 160, 14, 14)  82080       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/3x3 (Conv2D)       (None, 224, 14, 14)  226016      inception_4b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/5x5 (Conv2D)       (None, 64, 14, 14)   38464       inception_4b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/pool_proj (Conv2D) (None, 64, 14, 14)   32832       inception_4b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512, 14, 14)  0           inception_4b/1x1[0][0]           \n",
      "                                                                 inception_4b/3x3[0][0]           \n",
      "                                                                 inception_4b/5x5[0][0]           \n",
      "                                                                 inception_4b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/3x3_reduce (Conv2D (None, 128, 14, 14)  65664       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/5x5_reduce (Conv2D (None, 24, 14, 14)   12312       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/pool (MaxPooling2D (None, 512, 14, 14)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/1x1 (Conv2D)       (None, 128, 14, 14)  65664       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/3x3 (Conv2D)       (None, 256, 14, 14)  295168      inception_4c/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/5x5 (Conv2D)       (None, 64, 14, 14)   38464       inception_4c/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/pool_proj (Conv2D) (None, 64, 14, 14)   32832       inception_4c/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 512, 14, 14)  0           inception_4c/1x1[0][0]           \n",
      "                                                                 inception_4c/3x3[0][0]           \n",
      "                                                                 inception_4c/5x5[0][0]           \n",
      "                                                                 inception_4c/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/3x3_reduce (Conv2D (None, 144, 14, 14)  73872       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/5x5_reduce (Conv2D (None, 32, 14, 14)   16416       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/pool (MaxPooling2D (None, 512, 14, 14)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/1x1 (Conv2D)       (None, 112, 14, 14)  57456       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/3x3 (Conv2D)       (None, 288, 14, 14)  373536      inception_4d/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/5x5 (Conv2D)       (None, 64, 14, 14)   51264       inception_4d/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/pool_proj (Conv2D) (None, 64, 14, 14)   32832       inception_4d/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 528, 14, 14)  0           inception_4d/1x1[0][0]           \n",
      "                                                                 inception_4d/3x3[0][0]           \n",
      "                                                                 inception_4d/5x5[0][0]           \n",
      "                                                                 inception_4d/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/3x3_reduce (Conv2D (None, 160, 14, 14)  84640       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/5x5_reduce (Conv2D (None, 32, 14, 14)   16928       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/pool (MaxPooling2D (None, 528, 14, 14)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/1x1 (Conv2D)       (None, 256, 14, 14)  135424      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/3x3 (Conv2D)       (None, 320, 14, 14)  461120      inception_4e/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/5x5 (Conv2D)       (None, 128, 14, 14)  102528      inception_4e/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/pool_proj (Conv2D) (None, 128, 14, 14)  67712       inception_4e/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 832, 14, 14)  0           inception_4e/1x1[0][0]           \n",
      "                                                                 inception_4e/3x3[0][0]           \n",
      "                                                                 inception_4e/5x5[0][0]           \n",
      "                                                                 inception_4e/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 832, 16, 16)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_4 (PoolHelper)      (None, 832, 16, 16)  0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool4/3x3_s2 (MaxPooling2D)     (None, 832, 7, 7)    0           pool_helper_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/3x3_reduce (Conv2D (None, 160, 7, 7)    133280      pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/5x5_reduce (Conv2D (None, 32, 7, 7)     26656       pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/pool (MaxPooling2D (None, 832, 7, 7)    0           pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/1x1 (Conv2D)       (None, 256, 7, 7)    213248      pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/3x3 (Conv2D)       (None, 320, 7, 7)    461120      inception_5a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/5x5 (Conv2D)       (None, 128, 7, 7)    102528      inception_5a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/pool_proj (Conv2D) (None, 128, 7, 7)    106624      inception_5a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 832, 7, 7)    0           inception_5a/1x1[0][0]           \n",
      "                                                                 inception_5a/3x3[0][0]           \n",
      "                                                                 inception_5a/5x5[0][0]           \n",
      "                                                                 inception_5a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/3x3_reduce (Conv2D (None, 192, 7, 7)    159936      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/5x5_reduce (Conv2D (None, 48, 7, 7)     39984       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/pool (MaxPooling2D (None, 832, 7, 7)    0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "loss1/ave_pool (AveragePooling2 (None, 512, 4, 4)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "loss2/ave_pool (AveragePooling2 (None, 528, 4, 4)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/1x1 (Conv2D)       (None, 384, 7, 7)    319872      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/3x3 (Conv2D)       (None, 384, 7, 7)    663936      inception_5b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/5x5 (Conv2D)       (None, 128, 7, 7)    153728      inception_5b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/pool_proj (Conv2D) (None, 128, 7, 7)    106624      inception_5b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "loss1/conv (Conv2D)             (None, 128, 4, 4)    65664       loss1/ave_pool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "loss2/conv (Conv2D)             (None, 128, 4, 4)    67712       loss2/ave_pool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1024, 7, 7)   0           inception_5b/1x1[0][0]           \n",
      "                                                                 inception_5b/3x3[0][0]           \n",
      "                                                                 inception_5b/5x5[0][0]           \n",
      "                                                                 inception_5b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           loss1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           loss2/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool5/7x7_s2 (AveragePooling2D) (None, 1024, 1, 1)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "loss1/fc (Dense)                (None, 1024)         2098176     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss2/fc (Dense)                (None, 1024)         2098176     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1024)         0           pool5/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           loss1/fc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           loss2/fc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss1/classifier (Dense)        (None, 1000)         1025000     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss2/classifier (Dense)        (None, 1000)         1025000     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss3/classifier (Dense)        (None, 1000)         1025000     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head1 (Activation)              (None, 1000)         0           loss1/classifier[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "head2 (Activation)              (None, 1000)         0           loss2/classifier[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prob (Activation)               (None, 1000)         0           loss3/classifier[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 13,378,280\n",
      "Trainable params: 13,378,280\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-32cb9c2f41f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mslave_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslave_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "slave_model.summary()\n",
    "plot_model(slave_model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "OK\n",
      "Prunning The 0 Layer at 0%\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a969b3e4a236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m                                       \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                                       \u001b[0mmax_queue_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                                       shuffle = True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-a12cb6df6684>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    slave_model = create_googlenet('googlenet_weights_TF.h5', trainable = True)\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    slave_model.compile(optimizer=sgd, loss='categorical_crossentropy', loss_weights = {\"prob\": 1,\n",
    "                                                                                    \"head2\": 0.3,\n",
    "                                                                                    \"head1\": 0.3})\n",
    "\n",
    "    master_model = create_googlenet('googlenet_weights_TF.h5', trainable = False)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for index in range(0, 5):\n",
    "        for percentage in range(0, 60, 10):\n",
    "            weights = slave_model.get_layer(name = layer_names[index]).get_weights()\n",
    "            weights_flattened = np.concatenate((np.ndarray.flatten(weights[0]), np.ndarray.flatten(weights[1])))\n",
    "\n",
    "            sorted_weights = np.sort(np.abs(weights_flattened))\n",
    "\n",
    "            sorted_weights[int(percentage/100*weights_flattened.shape[0]):] = 99999\n",
    "\n",
    "            #weights_recovered = weights_flattened[0:np.ndarray.flatten(weights[0]).shape[0]].reshape(weights[0].shape)\n",
    "\n",
    "            pruned_weights_indices1 = np.intersect1d(np.ndarray.flatten(weights[0]), sorted_weights, return_indices = True)[1]\n",
    "\n",
    "            pruned_weights1 = np.ndarray.flatten(weights[0])\n",
    "            pruned_weights1[pruned_weights_indices1] = 0.0\n",
    "            pruned_weights1 = pruned_weights1.reshape(weights[0].shape)\n",
    "\n",
    "\n",
    "            pruned_weights_indices2 = np.intersect1d(np.abs(np.ndarray.flatten(weights[1])), sorted_weights, return_indices = True)[1]\n",
    "\n",
    "            pruned_weights2 = np.ndarray.flatten(weights[1])\n",
    "            pruned_weights2[pruned_weights_indices2] = 0.0\n",
    "            pruned_weights2 = pruned_weights2.reshape(weights[1].shape)\n",
    "\n",
    "            pruned_weights_layer = [pruned_weights1, pruned_weights2]\n",
    "\n",
    "            slave_model.get_layer(name = layer_names[index]).set_weights(pruned_weights_layer)\n",
    "\n",
    "            print(\"Prunning The \" + str(index) + \" Layer at \" + str(percentage) + \"%\\n\")\n",
    "\n",
    "            slave_model.fit_generator(data_generator(),\n",
    "                                      steps_per_epoch = 14267,\n",
    "                                      epochs = 10,\n",
    "                                      verbose = 1,\n",
    "                                      max_queue_size = 100,\n",
    "                                      shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from theano import function, config, shared, tensor\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0,force_device=True,floatX=float32\"\n",
    "import theano\n",
    "from theano import function, config, shared, tensor\n",
    "\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], tensor.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, tensor.Elemwise) and\n",
    "              ('Gpu' not in type(x.op).__name__)\n",
    "              for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OneLab_TF.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
